{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the Data\n",
    "\n",
    "Welcome to the cumulative project on clustering algorithms! In this project, we will be investigating the way people think about masculinity by applying the KMeans algorithm to data from  <a href=\"https://fivethirtyeight.com/\" target = \"_blank\">FiveThirtyEight</a>. FiveThirtyEight is a popular website known for their use of statistical analysis in many of their stories.\n",
    "\n",
    "To begin, take a look at `masculinity-survey.pdf`. FiveThirtyEight and WNYC studios used this survey to get their male readers' thoughts on masculinity. After looking through some of the questions asked, take a look at FiveThirtyEight's article <a href=\"https://fivethirtyeight.com/features/what-do-men-think-it-means-to-be-a-man/\" target = \"_blank\">What Do Men Think It Means To Be A Man?</a> to see their major takeaways. We're going to try to find more insights using machine learning.\n",
    "\n",
    "In the code block below, we've loaded `masculinity.csv` into a DataFrame named `survey`. This file contains the raw responses to the masculinity survey. Let's start getting a sense of how this data is structured. Try to answer these questions using your Pandas knowledge:\n",
    "* What are the names of the columns? How do those columns relate to the questions in the PDF?\n",
    "* How many rows are there?\n",
    "* How is a question with multiple parts, like question 7, represented in the DataFrame?\n",
    "* How many people said they often ask a friend for professional advice? This is the first sub-question in question 7.\n",
    "\n",
    "To answer that last question, use the `value_counts()` function. For example, `df[\"col_a\"].value_counts()` gives you a nice summary of the values found in `\"col_a\"` of the DataFrame `df`.\n",
    "\n",
    "You may also want to print `survey.head()` to get a sense of all of the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'StartDate', 'EndDate', 'q0001', 'q0002', 'q0004_0001',\n",
      "       'q0004_0002', 'q0004_0003', 'q0004_0004', 'q0004_0005', 'q0004_0006',\n",
      "       'q0005', 'q0007_0001', 'q0007_0002', 'q0007_0003', 'q0007_0004',\n",
      "       'q0007_0005', 'q0007_0006', 'q0007_0007', 'q0007_0008', 'q0007_0009',\n",
      "       'q0007_0010', 'q0007_0011', 'q0008_0001', 'q0008_0002', 'q0008_0003',\n",
      "       'q0008_0004', 'q0008_0005', 'q0008_0006', 'q0008_0007', 'q0008_0008',\n",
      "       'q0008_0009', 'q0008_0010', 'q0008_0011', 'q0008_0012', 'q0009',\n",
      "       'q0010_0001', 'q0010_0002', 'q0010_0003', 'q0010_0004', 'q0010_0005',\n",
      "       'q0010_0006', 'q0010_0007', 'q0010_0008', 'q0011_0001', 'q0011_0002',\n",
      "       'q0011_0003', 'q0011_0004', 'q0011_0005', 'q0012_0001', 'q0012_0002',\n",
      "       'q0012_0003', 'q0012_0004', 'q0012_0005', 'q0012_0006', 'q0012_0007',\n",
      "       'q0013', 'q0014', 'q0015', 'q0017', 'q0018', 'q0019_0001', 'q0019_0002',\n",
      "       'q0019_0003', 'q0019_0004', 'q0019_0005', 'q0019_0006', 'q0019_0007',\n",
      "       'q0020_0001', 'q0020_0002', 'q0020_0003', 'q0020_0004', 'q0020_0005',\n",
      "       'q0020_0006', 'q0021_0001', 'q0021_0002', 'q0021_0003', 'q0021_0004',\n",
      "       'q0022', 'q0024', 'q0025_0001', 'q0025_0002', 'q0025_0003', 'q0026',\n",
      "       'q0028', 'q0029', 'q0030', 'q0034', 'q0035', 'q0036', 'race2',\n",
      "       'racethn4', 'educ3', 'educ4', 'age3', 'kids', 'orientation', 'weight'],\n",
      "      dtype='object')\n",
      "1189\n",
      "Sometimes                    537\n",
      "Rarely                       324\n",
      "Often                        142\n",
      "Never, but open to it        123\n",
      "Never, and not open to it     53\n",
      "No answer                     10\n",
      "Name: q0007_0001, dtype: int64\n",
      "   Unnamed: 0     StartDate       EndDate               q0001  \\\n",
      "0           1  5/10/18 4:01  5/10/18 4:06  Somewhat masculine   \n",
      "1           2  5/10/18 6:30  5/10/18 6:53  Somewhat masculine   \n",
      "2           3  5/10/18 7:02  5/10/18 7:09      Very masculine   \n",
      "3           4  5/10/18 7:27  5/10/18 7:31      Very masculine   \n",
      "4           5  5/10/18 7:35  5/10/18 7:42      Very masculine   \n",
      "\n",
      "                q0002                  q0004_0001                  q0004_0002  \\\n",
      "0  Somewhat important                Not selected                Not selected   \n",
      "1  Somewhat important  Father or father figure(s)                Not selected   \n",
      "2   Not too important  Father or father figure(s)                Not selected   \n",
      "3   Not too important  Father or father figure(s)  Mother or mother figure(s)   \n",
      "4      Very important                Not selected                Not selected   \n",
      "\n",
      "             q0004_0003    q0004_0004    q0004_0005  ...               q0035  \\\n",
      "0          Not selected   Pop culture  Not selected  ...     Middle Atlantic   \n",
      "1          Not selected  Not selected  Not selected  ...  East North Central   \n",
      "2          Not selected  Not selected  Not selected  ...  East North Central   \n",
      "3  Other family members  Not selected  Not selected  ...  East North Central   \n",
      "4  Other family members  Not selected  Not selected  ...  East North Central   \n",
      "\n",
      "                      q0036      race2  racethn4            educ3  \\\n",
      "0  Windows Desktop / Laptop  Non-white  Hispanic  College or more   \n",
      "1        iOS Phone / Tablet      White     White     Some college   \n",
      "2  Windows Desktop / Laptop      White     White  College or more   \n",
      "3  Windows Desktop / Laptop      White     White     Some college   \n",
      "4  Windows Desktop / Laptop      White     White  College or more   \n",
      "\n",
      "             educ4       age3          kids   orientation    weight  \n",
      "0  College or more    35 - 64   No children  Gay/Bisexual  1.714026  \n",
      "1     Some college  65 and up  Has children      Straight  1.247120  \n",
      "2  College or more    35 - 64  Has children      Straight  0.515746  \n",
      "3     Some college  65 and up  Has children     No answer  0.600640  \n",
      "4  College or more    35 - 64   No children      Straight  1.033400  \n",
      "\n",
      "[5 rows x 98 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "survey = pd.read_csv(\"masculinity.csv\")\n",
    "print(survey.columns)\n",
    "print(len(survey))\n",
    "print(survey[\"q0007_0001\"].value_counts())\n",
    "print(survey.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping the Data\n",
    "\n",
    "In order for us to start thinking about using the KMeans algorithm with this data, we need to first figure out how to turn these responses into numerical data. Let's once again consider question 7. We can't cluster the data using the phrases `\"Often\"` or `\"Rarely\"`, but we can turn those phrases into numbers. For example, we could map the data in the following way: \n",
    "* `\"Often\"` -> `4`\n",
    "* `\"Sometimes\"` ->  `3`\n",
    "* `\"Rarely\"` -> `2` \n",
    "* `\"Never, but open to it\"` -> `1`\n",
    "* `\"Never, and not open to it\"` -> `0`.\n",
    "\n",
    "Note that it's important that these responses are somewhat linear. `\"Often\"` is at one end of the spectrum with `\"Never, and not open to it\"` at the other. The other values fall in sequence between the two. You could perform a similar mapping for the `\"educ4\"` responses (question 29), but there isn't an obvious linear progression in the `\"racethn4\"` responses (question 28).\n",
    "\n",
    "In order to do this transformation, use the `map()` function. `map()` takes a dictionary as a parameter. For example, the following line of code would turn all the `\"A\"`s into `1`s and all the `\"B\"`s into `2`s in the column `\"col_one\"`.\n",
    "\n",
    "```py\n",
    "df[\"col_one\"] = df[\"col_one\"].map({\"A\": 1, \"B\": 2})\n",
    "```\n",
    "\n",
    "We've given you a list of the columns that should be mapped. Loop through the values of the list and map each column using the mapping described above.\n",
    "\n",
    "Be careful of your spelling! Punctuation and whitespace is important. Take a look at the `value_counts()` of one of these columns to see if the mapping worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    537\n",
      "2.0    324\n",
      "4.0    142\n",
      "1.0    123\n",
      "0.0     53\n",
      "Name: q0007_0001, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols_to_map = [\"q0007_0001\", \"q0007_0002\", \"q0007_0003\", \"q0007_0004\",\n",
    "       \"q0007_0005\", \"q0007_0006\", \"q0007_0007\", \"q0007_0008\", \"q0007_0009\",\n",
    "       \"q0007_0010\", \"q0007_0011\"]\n",
    "\n",
    "for col in cols_to_map:\n",
    "    survey[col] = survey[col].map({\"Never, and not open to it\": 0, \"Never, but open to it\": 1, \"Rarely\": 2, \"Sometimes\": 3, \"Often\": 4})\n",
    "    \n",
    "print(survey['q0007_0001'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Data\n",
    "\n",
    "We now have 11 different features that we could use in our KMeans algorithm. Before we jump into clustering, let's graph some of these features on a 2D graph. Call `plt.scatter` using `survey[\"q0007_0001\"]` and `survey[\"q0007_0002\"]` as parameters. Include `alpha = 0.1`. We want to include `alpha` because many of the data points will be on top of each other. Adding `alpha` will make the points appear more solid if there are many stacked on top of each other.\n",
    "\n",
    "Include axis labels on your graph. The x-axis corresponds with the first column you gave the `scatter()` function. So in this case, it corresponds to the question about asking a friend for professional advice.\n",
    "\n",
    "Does it make sense that there are few points in the top left and bottom right corners of the graph? Why? Try graphing other dimensions against each other. Are there any combinations that give you surprising results?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(survey[\"q0007_0001\"], survey[\"q0007_0002\"], alpha = 0.1)\n",
    "plt.xlabel(\"Ask a friend for professional advice\")\n",
    "plt.ylabel(\"Ask a friend for personal advice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the KMeans Model\n",
    "\n",
    "It's now time to start clustering! There are so many interesting questions we could ask about this data. Let's start by seeing if clusters form based on traditionally masculine concepts. \n",
    "\n",
    "Take a look at the first four sub-questions in question 7. Those four activities aren't necessarily seen as traditionally masculine. On the other hand, sub-questions 5, 8, and 9 are often seen as very masculine activities. What would happen if we found 2 clusters based on those 7 questions? Would we find clusters that represent traditionally feminine and traditionally masculine people? Let's find out.\n",
    "\n",
    "We need to first drop all of the rows that contain a `NaN` value in any of the columns we're interested in. Create a new variable named `rows_to_cluster` and set it equal to the result of calling `dropna` on `survey`. `dropna` should have a parameter `subset` equal to a list of the 7 columns we want. If you don't include `subset`, the function will drop all rows that have an `NaN` in *any* column. This would drop almost all the rows in the dataframe!\n",
    "\n",
    "Create a `KMeans` object named `classifier` where `n_clusters = 2`. Call `classifier`'s `.fit()` method. The parameter of `.fit()` should be the 7 columns we're interested in. For example, the following line of code will fit the model based on the columns `\"col_one\"` and `\"col_two\"` of the Dataframe `df`. \n",
    "\n",
    "```py\n",
    "classifier.fit(df[[\"col_one\", \"col_two\"]])\n",
    "```\n",
    "\n",
    "Make sure to only include the columns that you want to train off of. Make sure to use `rows_to_cluster` rather than `survey` to avoid including those `NaN`s!\n",
    "\n",
    "\n",
    "\n",
    "After fitting your model, print out the model's `cluster_centers_`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.87830688 1.84391534 0.85185185 1.72486772 0.57142857 2.64021164\n",
      "  1.97089947]\n",
      " [2.84548105 2.81632653 2.84110787 2.39941691 0.69387755 3.06997085\n",
      "  2.90087464]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "rows_to_cluster = survey.dropna(subset = [\"q0007_0001\", \"q0007_0002\", \"q0007_0003\", \"q0007_0004\", \"q0007_0005\", \"q0007_0008\", \"q0007_0009\"])\n",
    "classifier = KMeans(n_clusters = 2)\n",
    "classifier.fit(rows_to_cluster[[\"q0007_0001\", \"q0007_0002\", \"q0007_0003\", \"q0007_0004\", \"q0007_0005\", \"q0007_0008\", \"q0007_0009\"]])\n",
    "print(classifier.cluster_centers_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the Cluster Members\n",
    "\n",
    "When we look at the two clusters, the first four numbers represent the traditionally feminine activities and the last three represent the traditionally masculine activities. If the data points separated into a feminine cluser and a masculine cluseter, we would expect to see one cluster to have high values for the first four numbers and the other cluster to have high values for the last three numbers.\n",
    "\n",
    "Instead, the first cluster has a higher value in every feature. Since a higher number means the person was more likely to \"often\" do something, the clusters seem to represent \"people who do things\" and \"people who don't do things\".\n",
    "\n",
    "We might be able to find out more information about these clusters by looking at the specific members of each cluster. Print `classifier.labels_`. This list shows which cluster every row in the DataFrame corresponds to.\n",
    "\n",
    "For example,  if `classifier.labels_` was `[1, 0 ,1]`, then the first row in the DataFrame would be in cluster one, the second row would be in cluster 0, and the third row would be in cluster one. A row represents one persons answers to every question in the survey.\n",
    "\n",
    "Create two new empty lists named `cluster_zero_indices` and `cluster_one_indices`. Loop through `classifier.labels_` and whenever a label is `0` add that index to `cluster_zero_indices`. Do the same whenever a label is a `1`.\n",
    "\n",
    "Print `cluster_zero_indices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 0 0]\n",
      "[1, 4, 6, 7, 9, 10, 12, 14, 17, 18, 19, 24, 29, 35, 39, 42, 49, 51, 52, 53, 54, 55, 57, 58, 62, 63, 65, 66, 75, 78, 79, 82, 84, 86, 87, 88, 89, 90, 92, 94, 95, 97, 98, 101, 106, 107, 109, 113, 116, 117, 118, 119, 123, 128, 129, 130, 131, 132, 134, 139, 142, 143, 154, 172, 175, 176, 178, 179, 180, 181, 184, 187, 189, 195, 196, 198, 199, 201, 209, 212, 222, 229, 230, 231, 233, 236, 237, 240, 241, 247, 248, 249, 250, 256, 260, 261, 263, 264, 272, 275, 281, 283, 284, 286, 288, 291, 296, 297, 299, 300, 301, 305, 310, 311, 325, 328, 331, 336, 337, 340, 341, 343, 347, 350, 351, 353, 361, 367, 369, 377, 378, 390, 391, 392, 393, 394, 396, 397, 398, 399, 409, 410, 411, 412, 415, 417, 418, 419, 425, 428, 429, 432, 449, 454, 455, 457, 459, 461, 463, 468, 470, 471, 476, 477, 478, 484, 489, 490, 493, 494, 496, 498, 499, 502, 508, 509, 510, 515, 516, 521, 523, 525, 526, 529, 531, 533, 542, 546, 549, 555, 556, 559, 560, 562, 563, 564, 566, 567, 570, 577, 579, 580, 585, 588, 589, 592, 593, 599, 603, 610, 616, 617, 619, 620, 622, 625, 626, 629, 631, 634, 636, 637, 638, 639, 649, 651, 654, 655, 656, 659, 662, 669, 677, 681, 683, 685, 686, 687, 691, 692, 696, 697, 702, 710, 718, 719, 720, 721, 722, 723, 726, 728, 730, 736, 738, 741, 744, 745, 748, 749, 750, 751, 758, 759, 762, 766, 768, 769, 772, 775, 776, 777, 778, 782, 783, 787, 788, 789, 790, 792, 794, 795, 797, 799, 800, 801, 803, 805, 810, 814, 821, 826, 827, 831, 837, 839, 843, 848, 849, 853, 856, 858, 860, 868, 871, 872, 874, 875, 879, 880, 882, 883, 884, 886, 892, 894, 895, 896, 897, 898, 900, 901, 902, 904, 911, 914, 918, 919, 922, 923, 924, 929, 932, 936, 939, 943, 948, 954, 958, 961, 962, 963, 967, 968, 970, 971, 974, 978, 982, 985, 987, 989, 991, 993, 998, 1000, 1003, 1007, 1011, 1013, 1014, 1016, 1025, 1036, 1037, 1038, 1039, 1042, 1045, 1046, 1048, 1050, 1054, 1055, 1057, 1061, 1062, 1063]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.labels_)\n",
    "\n",
    "cluster_zero_indices = []\n",
    "cluster_one_indices = []\n",
    "for i in range(len(classifier.labels_)):\n",
    "    if classifier.labels_[i] == 0:\n",
    "        cluster_zero_indices.append(i)\n",
    "    elif classifier.labels_[i] == 1:\n",
    "        cluster_one_indices.append(i)\n",
    "        \n",
    "print(cluster_zero_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the Cluster Members\n",
    "\n",
    "Now that we have the indices for each cluster, let's look at some stats about these two clusters. You can get the rows of the DataFrame that correspond to cluster zero by doing the following:\n",
    "\n",
    "```py\n",
    "cluster_zero_df = rows_to_cluster.iloc[cluster_zero_indices]\n",
    "```\n",
    "\n",
    "Do the same for `cluster_one_df`.\n",
    "\n",
    "Finally, let's look at some information about these two clusters. Print the `value_counts()` of the `educ4` column of each cluster. What do you notice? Try looking at different columns. For example, are the people in cluster zero significantly older than those in cluster one? You can look at the `age3` column to see.\n",
    "\n",
    "If you divide the result of `value_counts()` by the size of the cluster, you get the percentage of people in each category rather than the total number. This will make it easier to compare the two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some college            0.314815\n",
      "College or more         0.285714\n",
      "Post graduate degree    0.251323\n",
      "High school or less     0.145503\n",
      "Name: educ4, dtype: float64\n",
      "\n",
      "Post graduate degree    0.365889\n",
      "College or more         0.330904\n",
      "Some college            0.230321\n",
      "High school or less     0.072886\n",
      "Name: educ4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cluster_zero_df = rows_to_cluster.iloc[cluster_zero_indices]\n",
    "cluster_one_df = rows_to_cluster.iloc[cluster_one_indices]\n",
    "\n",
    "print(cluster_zero_df['educ4'].value_counts()/len(cluster_zero_df))\n",
    "print()\n",
    "print(cluster_one_df['educ4'].value_counts()/len(cluster_one_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore on Your Own\n",
    "\n",
    "Great work! You've found out that by answering those 7 questions people don't fall into a \"masculine\" category or a \"feminine\" category. Instead, they seem to be divided by their level of education!\n",
    "\n",
    "Now it's time for you to explore this data on your own. In this project, we've really focused on question 7 and its sub-questions. Take a look at some of the other questions in the survey and try to ask yourself some interesting questions. Here's a list of questions you could dive into:\n",
    "\n",
    "* Which demographic features have stronger correlations with ideas of masculinity (sexual orientation, age, race, marital status, parenthood?)\n",
    "* Are certain beliefs or actions linked to more self-described masculine or feminine individuals?\n",
    "* How do insecurities change as people grow older?\n",
    "\n",
    "\n",
    "Special thanks to the team at FiveThirtyEight and specifically Dhrumil Mehta for giving us access to the data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
